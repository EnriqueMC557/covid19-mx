{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 01:22:58.358571: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-29 01:22:58.384550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 01:22:58.824777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-29 01:22:59.691554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:22:59.706390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:22:59.706495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import paths\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEXO</th>\n",
       "      <th>TIPO_PACIENTE</th>\n",
       "      <th>FECHA_INGRESO</th>\n",
       "      <th>FECHA_SINTOMAS</th>\n",
       "      <th>DEFUNCION</th>\n",
       "      <th>INTUBADO</th>\n",
       "      <th>NEUMONIA</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>EMBARAZO</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>EPOC</th>\n",
       "      <th>ASMA</th>\n",
       "      <th>INMUSUPR</th>\n",
       "      <th>HIPERTENSION</th>\n",
       "      <th>OTRA_COM</th>\n",
       "      <th>CARDIOVASCULAR</th>\n",
       "      <th>OBESIDAD</th>\n",
       "      <th>RENAL_CRONICA</th>\n",
       "      <th>TABAQUISMO</th>\n",
       "      <th>OTRO_CASO</th>\n",
       "      <th>CLASIFICACION_FINAL</th>\n",
       "      <th>PAIS_NACIONALIDAD</th>\n",
       "      <th>PAIS_ORIGEN</th>\n",
       "      <th>UCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26037</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33460</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93297</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12804</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-19</td>\n",
       "      <td>2022-06-19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77211</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89798</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17067</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62522</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42864</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEXO  TIPO_PACIENTE FECHA_INGRESO FECHA_SINTOMAS  DEFUNCION  INTUBADO  \\\n",
       "26037     1              2    2022-02-05     2022-02-05          1       2.0   \n",
       "33460     2              2    2022-01-16     2022-01-11          1       2.0   \n",
       "93297     2              2    2022-01-20     2022-01-10          1       2.0   \n",
       "12804     2              1    2022-06-19     2022-06-19          0       3.0   \n",
       "77211     2              2    2022-01-31     2022-01-29          1       2.0   \n",
       "2647      2              2    2022-01-15     2022-01-14          1       2.0   \n",
       "89798     1              1    2022-12-27     2022-12-25          0       3.0   \n",
       "17067     2              1    2022-01-24     2022-01-15          0       3.0   \n",
       "62522     2              1    2022-07-22     2022-07-17          0       3.0   \n",
       "42864     2              2    2022-12-01     2022-12-01          1       1.0   \n",
       "\n",
       "       NEUMONIA  EDAD  EMBARAZO  DIABETES  EPOC  ASMA  INMUSUPR  HIPERTENSION  \\\n",
       "26037       2.0  82.0       2.0       2.0   2.0   2.0       2.0           1.0   \n",
       "33460       2.0  80.0       2.0       1.0   2.0   2.0       2.0           1.0   \n",
       "93297       2.0  95.0       2.0       2.0   2.0   2.0       2.0           1.0   \n",
       "12804       2.0  76.0       2.0       2.0   2.0   2.0       2.0           1.0   \n",
       "77211       2.0  95.0       2.0       2.0   1.0   2.0       2.0           1.0   \n",
       "2647        2.0  69.0       2.0       2.0   2.0   2.0       2.0           2.0   \n",
       "89798       2.0  38.0       2.0       2.0   2.0   2.0       2.0           2.0   \n",
       "17067       2.0  49.0       2.0       2.0   2.0   2.0       2.0           2.0   \n",
       "62522       2.0  29.0       2.0       2.0   2.0   2.0       2.0           2.0   \n",
       "42864       2.0  61.0       2.0       2.0   2.0   2.0       2.0           2.0   \n",
       "\n",
       "       OTRA_COM  CARDIOVASCULAR  OBESIDAD  RENAL_CRONICA  TABAQUISMO  \\\n",
       "26037       2.0             2.0       2.0            2.0         2.0   \n",
       "33460       2.0             2.0       2.0            2.0         2.0   \n",
       "93297       2.0             2.0       2.0            2.0         2.0   \n",
       "12804       2.0             2.0       2.0            2.0         2.0   \n",
       "77211       2.0             2.0       2.0            2.0         2.0   \n",
       "2647        2.0             2.0       2.0            2.0         2.0   \n",
       "89798       2.0             2.0       2.0            2.0         2.0   \n",
       "17067       2.0             2.0       1.0            2.0         1.0   \n",
       "62522       2.0             2.0       2.0            2.0         2.0   \n",
       "42864       2.0             2.0       1.0            2.0         2.0   \n",
       "\n",
       "       OTRO_CASO  CLASIFICACION_FINAL  PAIS_NACIONALIDAD  PAIS_ORIGEN  UCI  \n",
       "26037        2.0                    3              109.0          0.0  2.0  \n",
       "33460        2.0                    3              109.0          0.0  2.0  \n",
       "93297        2.0                    3              109.0          0.0  2.0  \n",
       "12804        2.0                    3              109.0          0.0  3.0  \n",
       "77211        2.0                    7              109.0          0.0  2.0  \n",
       "2647         2.0                    7              109.0          0.0  2.0  \n",
       "89798        2.0                    7              109.0          0.0  3.0  \n",
       "17067        1.0                    7              109.0          0.0  3.0  \n",
       "62522        2.0                    3              109.0          0.0  3.0  \n",
       "42864        NaN                    7              109.0          0.0  2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(paths.DATA_PATH + \"/COVID19MX_sample.csv\")\n",
    "data.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93458 entries, 0 to 93457\n",
      "Data columns (total 24 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   SEXO                 93458 non-null  int64  \n",
      " 1   TIPO_PACIENTE        93458 non-null  int64  \n",
      " 2   FECHA_INGRESO        93458 non-null  object \n",
      " 3   FECHA_SINTOMAS       93458 non-null  object \n",
      " 4   DEFUNCION            93458 non-null  int64  \n",
      " 5   INTUBADO             93186 non-null  float64\n",
      " 6   NEUMONIA             92920 non-null  float64\n",
      " 7   EDAD                 93269 non-null  float64\n",
      " 8   EMBARAZO             93147 non-null  float64\n",
      " 9   DIABETES             93123 non-null  float64\n",
      " 10  EPOC                 93137 non-null  float64\n",
      " 11  ASMA                 93154 non-null  float64\n",
      " 12  INMUSUPR             93152 non-null  float64\n",
      " 13  HIPERTENSION         93155 non-null  float64\n",
      " 14  OTRA_COM             92299 non-null  float64\n",
      " 15  CARDIOVASCULAR       93149 non-null  float64\n",
      " 16  OBESIDAD             93221 non-null  float64\n",
      " 17  RENAL_CRONICA        93162 non-null  float64\n",
      " 18  TABAQUISMO           93144 non-null  float64\n",
      " 19  OTRO_CASO            90115 non-null  float64\n",
      " 20  CLASIFICACION_FINAL  93458 non-null  int64  \n",
      " 21  PAIS_NACIONALIDAD    93458 non-null  float64\n",
      " 22  PAIS_ORIGEN          93458 non-null  float64\n",
      " 23  UCI                  93185 non-null  float64\n",
      "dtypes: float64(18), int64(4), object(2)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (74766, 21)\n",
      "Test: (18692, 21)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=[\"DEFUNCION\", \"FECHA_INGRESO\", \"FECHA_SINTOMAS\"]).to_numpy()\n",
    "Y = data[[\"DEFUNCION\"]].to_numpy()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=557)\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 01:22:59.837470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:22:59.837601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:22:59.837655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:23:00.166321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:23:00.166437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:23:00.166491: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-29 01:23:00.166540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9418 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2023-06-29 01:23:00.272688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:00.272798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:01.486390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:01.486493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "True              |True              |structured_data_block_1/normalize\n",
      "2                 |2                 |structured_data_block_1/dense_block_1/num_layers\n",
      "False             |False             |structured_data_block_1/dense_block_1/use_batchnorm\n",
      "0                 |0                 |structured_data_block_1/dense_block_1/dropout\n",
      "32                |32                |structured_data_block_1/dense_block_1/units_0\n",
      "32                |32                |structured_data_block_1/dense_block_1/units_1\n",
      "0                 |0                 |classification_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 01:23:02.247288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-06-29 01:23:02.247460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 01:23:03.837284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 01:23:03.837456: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:05.452109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-06-29 01:23:05.452284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-06-29 01:23:07.070825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:07.071003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 01:23:09.101350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-06-29 01:23:09.101525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-06-29 01:23:10.677674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 01:23:10.677852: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 01:23:12.493936: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:12.494113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-06-29 01:23:14.336635: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-06-29 01:23:14.336826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-06-29 01:23:15.676951: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-06-29 01:23:15.677168: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:17.089888: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2023-06-29 01:23:17.090071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 01:23:19.037306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-29 01:23:19.037537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:21.274359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-06-29 01:23:21.274537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-06-29 01:23:22.869959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_20' with dtype int64 and shape [74766,1]\n",
      "\t [[{{node Placeholder/_20}}]]\n",
      "2023-06-29 01:23:22.870137: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74766,21]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/GPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     clf \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mStructuredDataClassifier(\n\u001b[1;32m      3\u001b[0m         overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_trials\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m      4\u001b[0m     )\n\u001b[0;32m----> 5\u001b[0m     clf\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      6\u001b[0m         x\u001b[39m=\u001b[39;49mX_train, y\u001b[39m=\u001b[39;49mY_train,\n\u001b[1;32m      7\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m      8\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/autokeras/tasks/structured_data.py:326\u001b[0m, in \u001b[0;36mStructuredDataClassifier.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    280\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    281\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    288\u001b[0m ):\n\u001b[1;32m    289\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search for the best model and hyperparameters for the AutoModel.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[39m    # Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m            validation loss values and validation metrics values (if applicable).\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     history \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    327\u001b[0m         x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    328\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    329\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    330\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    331\u001b[0m         validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    332\u001b[0m         validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    333\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    334\u001b[0m     )\n\u001b[1;32m    335\u001b[0m     \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/autokeras/tasks/structured_data.py:139\u001b[0m, in \u001b[0;36mBaseStructuredDataPipeline.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         validation_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_from_csv(x_val, y_val)\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_in_fit(x)\n\u001b[0;32m--> 139\u001b[0m history \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    140\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    141\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    142\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    143\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    144\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    145\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    146\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/autokeras/auto_model.py:292\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m validation_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m validation_split:\n\u001b[1;32m    288\u001b[0m     dataset, validation_data \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39msplit_dataset(\n\u001b[1;32m    289\u001b[0m         dataset, validation_split\n\u001b[1;32m    290\u001b[0m     )\n\u001b[0;32m--> 292\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    293\u001b[0m     x\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m    294\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    295\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    296\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    297\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    298\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    299\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/autokeras/engine/tuner.py:193\u001b[0m, in \u001b[0;36mAutoTuner.search\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 193\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    194\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, callbacks\u001b[39m=\u001b[39;49mnew_callbacks, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    197\u001b[0m \u001b[39m# Train the best model use validation data.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# Train the best model with enough number of epochs.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m validation_split \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m early_stopping_inserted:\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/autokeras/engine/tuner.py:99\u001b[0m, in \u001b[0;36mAutoTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m (\n\u001b[1;32m     93\u001b[0m     pipeline,\n\u001b[1;32m     94\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     95\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mvalidation_data\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     96\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_model_build(trial\u001b[39m.\u001b[39mhyperparameters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m pipeline\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_path(trial\u001b[39m.\u001b[39mtrial_id))\n\u001b[0;32m---> 99\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madapt(model, kwargs[\u001b[39m\"\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    101\u001b[0m _, history \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mfit_with_adaptive_batch_size(\n\u001b[1;32m    102\u001b[0m     model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mbatch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/autokeras/engine/tuner.py:136\u001b[0m, in \u001b[0;36mAutoTuner.adapt\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(dq):\n\u001b[1;32m    135\u001b[0m     layer, in_x \u001b[39m=\u001b[39m dq\u001b[39m.\u001b[39mpopleft()\n\u001b[0;32m--> 136\u001b[0m     layer\u001b[39m.\u001b[39;49madapt(in_x)\n\u001b[1;32m    137\u001b[0m     out_x \u001b[39m=\u001b[39m in_x\u001b[39m.\u001b[39mmap(layer)\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m next_layer \u001b[39min\u001b[39;00m get_output_layers(layer\u001b[39m.\u001b[39moutput):\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/autokeras/keras_layers.py:114\u001b[0m, in \u001b[0;36mMultiCategoryEncoding.adapt\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    113\u001b[0m data_column \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: tf\u001b[39m.\u001b[39mslice(x, [\u001b[39m0\u001b[39m, index], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]))\n\u001b[0;32m--> 114\u001b[0m encoding_layer\u001b[39m.\u001b[39;49madapt(data_column\u001b[39m.\u001b[39;49mmap(data_utils\u001b[39m.\u001b[39;49mcast_to_string))\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/keras/layers/preprocessing/string_lookup.py:409\u001b[0m, in \u001b[0;36mStringLookup.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madapt\u001b[39m(\u001b[39mself\u001b[39m, data, batch_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, steps\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Computes a vocabulary of string terms from tokens in a dataset.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[1;32m    362\u001b[0m \u001b[39m    Calling `adapt()` on a `StringLookup` layer is an alternative to passing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39m          argument is not supported with array inputs.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49madapt(data, batch_size\u001b[39m=\u001b[39;49mbatch_size, steps\u001b[39m=\u001b[39;49msteps)\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/keras/engine/base_preprocessing_layer.py:258\u001b[0m, in \u001b[0;36mPreprocessingLayer.adapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m    257\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m--> 258\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adapt_function(iterator)\n\u001b[1;32m    259\u001b[0m         \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m    260\u001b[0m             context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/mnt/Datos/.enviroments/ubu20/AutoDLp38/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = ak.StructuredDataClassifier(\n",
    "    overwrite=True, max_trials=2, num_classes=2,\n",
    ")\n",
    "clf.fit(\n",
    "    x=X_train, y=Y_train,\n",
    "    epochs=50, validation_split=0.25\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
